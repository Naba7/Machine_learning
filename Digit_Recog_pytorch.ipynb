{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2810)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3118)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7652, -1.4550],\n",
      "        [-1.2232,  0.1810]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5856,  2.1170],\n",
      "        [ 1.4962,  0.0328]])\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x10b508b70>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0579)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3826, -0.7275],\n",
      "        [-0.6116,  0.0905]])\n",
      "tensor([[ 0.3826, -0.7275],\n",
      "        [-0.6116,  0.0905]])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor(1.00000e-02 *\n",
      "       [[-0.0296, -0.0296, -0.0296,  ..., -0.0296, -0.0296, -0.0296],\n",
      "        [-0.0441, -0.0441, -0.0441,  ..., -0.0441, -0.0441, -0.0441],\n",
      "        [ 0.0177,  0.0177,  0.0177,  ...,  0.0177,  0.0177,  0.0177],\n",
      "        ...,\n",
      "        [ 0.4021,  0.4021,  0.4021,  ...,  0.4021,  0.4021,  0.4021],\n",
      "        [-0.1361, -0.1361, -0.1361,  ..., -0.1361, -0.1361, -0.1361],\n",
      "        [-0.0155, -0.0155, -0.0155,  ..., -0.0155, -0.0155, -0.0155]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 3.5691e-02,  2.1438e-02,  2.2862e-02,  ..., -1.3882e-02,\n",
      "         -2.3719e-02, -4.6573e-03],\n",
      "        [-3.2397e-03,  3.5117e-03, -1.5220e-03,  ...,  1.4400e-02,\n",
      "          2.8463e-03,  2.5381e-03],\n",
      "        [ 5.6122e-03,  4.8693e-03, -3.4507e-02,  ..., -2.8224e-02,\n",
      "         -1.2907e-02, -1.5818e-02],\n",
      "        ...,\n",
      "        [-1.4372e-02,  2.3948e-02,  2.8374e-02,  ..., -1.5817e-02,\n",
      "          3.2719e-02,  8.5537e-03],\n",
      "        [-1.1999e-02,  1.9462e-02,  1.3998e-02,  ..., -2.0170e-03,\n",
      "          1.4254e-02,  2.2238e-02],\n",
      "        [ 3.9955e-04,  4.8263e-03, -2.1819e-02,  ...,  1.2959e-02,\n",
      "         -4.4880e-03,  1.4609e-02]])\n",
      "Gradient - tensor(1.00000e-02 *\n",
      "       [[-0.2609, -0.2609, -0.2609,  ..., -0.2609, -0.2609, -0.2609],\n",
      "        [-0.0695, -0.0695, -0.0695,  ..., -0.0695, -0.0695, -0.0695],\n",
      "        [ 0.0514,  0.0514,  0.0514,  ...,  0.0514,  0.0514,  0.0514],\n",
      "        ...,\n",
      "        [ 0.0967,  0.0967,  0.0967,  ...,  0.0967,  0.0967,  0.0967],\n",
      "        [-0.1878, -0.1878, -0.1878,  ..., -0.1878, -0.1878, -0.1878],\n",
      "        [ 0.0281,  0.0281,  0.0281,  ...,  0.0281,  0.0281,  0.0281]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 3.5717e-02,  2.1464e-02,  2.2888e-02,  ..., -1.3856e-02,\n",
      "         -2.3693e-02, -4.6312e-03],\n",
      "        [-3.2327e-03,  3.5187e-03, -1.5150e-03,  ...,  1.4407e-02,\n",
      "          2.8533e-03,  2.5450e-03],\n",
      "        [ 5.6071e-03,  4.8642e-03, -3.4513e-02,  ..., -2.8230e-02,\n",
      "         -1.2912e-02, -1.5823e-02],\n",
      "        ...,\n",
      "        [-1.4381e-02,  2.3938e-02,  2.8365e-02,  ..., -1.5827e-02,\n",
      "          3.2709e-02,  8.5441e-03],\n",
      "        [-1.1981e-02,  1.9481e-02,  1.4016e-02,  ..., -1.9983e-03,\n",
      "          1.4272e-02,  2.2257e-02],\n",
      "        [ 3.9674e-04,  4.8235e-03, -2.1821e-02,  ...,  1.2956e-02,\n",
      "         -4.4908e-03,  1.4606e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8959971736234897\n",
      "Training loss: 0.8684300759644397\n",
      "Training loss: 0.537974218426864\n",
      "Training loss: 0.43723612014990626\n",
      "Training loss: 0.39094475933165945\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
